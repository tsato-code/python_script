# ------------------
# モジュールインポート
# ------------------
import itertools
import numpy as np
from MTS import *

# ------------------
# 定数パラメータ設定
# ------------------
IN_FILE = "../data/iris.csv"
OUT_DIR = "../out"

L8 = [
0,0,0,0,0,0,0,
0,0,0,1,1,1,1,
0,1,1,0,0,1,1,
0,1,1,1,1,0,0,
1,0,1,0,1,0,1,
1,0,1,1,0,1,0,
1,1,0,0,1,1,0,
1,1,0,1,0,0,1,
]

L16 = [
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,
0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,
0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,
0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,
0,1,1,0,0,1,1,1,1,0,0,1,1,0,0,
0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,
0,1,1,1,1,0,0,1,1,0,0,0,0,1,1,
1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,
1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,
1,0,1,1,0,1,0,0,1,0,1,1,0,1,0,
1,0,1,1,0,1,0,1,0,1,0,0,1,0,1,
1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,
1,1,0,0,1,1,0,1,0,0,1,1,0,0,1,
1,1,0,1,0,0,1,0,1,1,0,1,0,0,1,
1,1,0,1,0,0,1,1,0,0,1,0,1,1,0,
]

L32 = [
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,
0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,
0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,
0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,
0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,
0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,1,1,1,
0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,
0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,
0,1,1,0,0,1,1,1,1,0,0,1,1,0,0,0,0,1,1,0,0,1,1,1,1,0,0,1,1,0,0,
0,1,1,0,0,1,1,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,0,0,1,1,0,0,1,1,
0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,
0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,
0,1,1,1,1,0,0,1,1,0,0,0,0,1,1,0,0,1,1,1,1,0,0,1,1,0,0,0,0,1,1,
0,1,1,1,1,0,0,1,1,0,0,0,0,1,1,1,1,0,0,0,0,1,1,0,0,1,1,1,1,0,0,
1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,
1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,
1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,
1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,1,0,1,0,1,0,1,
1,0,1,1,0,1,0,0,1,0,1,1,0,1,0,0,1,0,1,1,0,1,0,0,1,0,1,1,0,1,0,
1,0,1,1,0,1,0,0,1,0,1,1,0,1,0,1,0,1,0,0,1,0,1,1,0,1,0,0,1,0,1,
1,0,1,1,0,1,0,1,0,1,0,0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,0,1,0,1,
1,0,1,1,0,1,0,1,0,1,0,0,1,0,1,1,0,1,0,0,1,0,1,0,1,0,1,1,0,1,0,
1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,
1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,
1,1,0,0,1,1,0,1,0,0,1,1,0,0,1,0,1,1,0,0,1,1,0,1,0,0,1,1,0,0,1,
1,1,0,0,1,1,0,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,0,1,1,0,0,1,1,0,
1,1,0,1,0,0,1,0,1,1,0,1,0,0,1,0,1,1,0,1,0,0,1,0,1,1,0,1,0,0,1,
1,1,0,1,0,0,1,0,1,1,0,1,0,0,1,1,0,0,1,0,1,1,0,1,0,0,1,0,1,1,0,
1,1,0,1,0,0,1,1,0,0,1,0,1,1,0,0,1,1,0,1,0,0,1,1,0,0,1,0,1,1,0,
1,1,0,1,0,0,1,1,0,0,1,0,1,1,0,1,0,0,1,0,1,1,0,0,1,1,0,1,0,0,1,
]

L64 = [
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0,0,0,0,0,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,
0,0,0,0,1,0,1,1,0,0,0,1,0,0,0,1,0,0,1,0,1,1,0,0,0,1,0,0,1,0,1,1,0,0,1,0,1,1,0,1,1,1,0,0,1,0,1,1,0,1,1,1,0,1,0,1,1,0,1,1,1,1,1,
0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,1,0,1,1,1,1,0,0,1,1,1,1,0,0,1,0,0,0,1,1,0,1,0,0,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,
0,0,0,1,0,0,1,0,0,0,0,1,1,0,0,0,1,0,0,1,0,1,1,0,0,0,1,0,1,1,0,1,1,0,1,1,0,1,1,0,1,1,1,0,0,1,0,1,1,0,1,1,1,0,0,1,1,1,0,1,1,1,1,
0,0,0,1,0,1,1,0,1,1,1,1,0,1,1,1,0,1,1,0,1,1,0,1,1,1,0,1,1,0,1,0,0,1,1,0,1,0,0,1,0,0,0,1,1,0,1,0,0,1,0,0,0,1,0,0,0,0,1,0,0,0,0,
0,0,0,1,1,0,0,1,0,0,0,0,1,0,0,1,1,0,1,1,1,0,1,0,0,1,1,0,0,1,1,0,1,0,0,1,1,0,1,1,0,0,1,0,1,1,1,0,1,1,0,0,1,1,0,0,0,1,1,0,0,0,0,
0,0,0,1,1,1,0,1,1,1,1,0,0,1,1,0,0,1,0,0,0,0,0,1,1,0,0,1,0,0,0,1,0,1,0,0,0,1,0,0,1,1,0,1,0,0,0,1,0,0,1,1,0,0,0,1,1,0,0,1,1,1,1,
0,0,1,0,0,0,0,1,1,0,0,0,0,1,0,0,0,1,0,0,0,1,1,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,1,1,0,1,1,1,1,0,0,0,1,1,0,1,1,1,0,1,1,1,1,0,1,1,1,
0,0,1,0,0,1,0,1,0,1,1,0,1,0,1,1,1,0,1,1,1,1,0,0,1,0,1,0,0,1,1,1,0,0,0,1,1,1,0,0,1,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,
0,0,1,0,1,0,1,0,1,0,0,1,0,1,0,1,0,1,1,0,1,0,1,1,0,0,0,1,1,0,1,1,1,1,1,0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,0,1,0,0,0,0,1,0,1,0,0,0,
0,0,1,0,1,1,1,0,0,1,1,1,1,0,1,0,1,0,0,1,0,0,0,0,1,1,1,0,1,1,0,0,0,0,1,1,0,0,0,1,0,1,0,0,1,1,0,0,0,1,0,1,0,1,0,1,1,0,1,0,1,1,1,
0,0,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,0,1,0,0,0,1,0,1,1,1,1,1,0,1,0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,1,0,1,1,0,0,1,0,0,0,0,1,1,0,0,0,
0,0,1,1,0,1,1,1,0,1,1,1,0,0,1,1,0,0,1,0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,0,1,1,0,0,0,1,0,1,0,0,1,1,0,0,1,1,1,0,0,1,1,1,
0,0,1,1,1,0,0,0,1,0,0,0,1,1,0,1,1,1,1,1,1,1,0,1,0,0,1,1,0,1,1,0,0,1,0,1,1,0,0,0,0,1,0,1,0,1,1,0,0,0,0,1,0,0,0,1,1,0,0,0,1,1,1,
0,0,1,1,1,1,0,0,0,1,1,0,0,0,1,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,1,1,0,0,0,0,1,1,1,1,0,1,0,1,0,0,1,1,1,1,0,1,1,0,0,0,1,1,1,0,0,0,
0,1,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,1,1,1,1,0,1,1,
0,1,0,0,0,1,0,0,1,0,1,0,1,1,0,1,1,1,1,1,1,0,1,0,0,1,0,1,0,1,1,1,1,0,1,0,0,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,1,0,0,0,0,1,0,0,
0,1,0,0,1,0,1,1,0,1,0,1,0,0,1,1,0,0,1,0,1,1,0,1,1,1,1,0,1,0,1,1,0,1,0,1,0,1,0,1,1,1,1,1,0,1,0,0,0,1,1,1,1,0,0,1,0,1,0,0,1,0,0,
0,1,0,0,1,1,1,1,1,0,1,1,1,1,0,0,1,1,0,1,0,1,1,0,0,0,0,1,1,1,0,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,1,1,1,0,0,0,0,1,0,0,1,0,1,1,0,1,1,
0,1,0,1,0,0,1,0,0,1,0,1,1,0,1,0,1,0,0,1,0,1,1,1,1,0,0,0,1,1,0,1,1,1,0,0,1,1,1,0,1,1,0,1,1,0,1,0,1,0,1,1,0,1,0,1,0,0,1,0,1,0,0,
0,1,0,1,0,1,1,0,1,0,1,1,0,1,0,1,0,1,1,0,1,1,0,0,0,1,1,1,1,0,1,0,0,0,0,1,0,0,0,1,0,0,1,0,0,1,0,1,0,1,0,0,1,0,0,0,1,1,0,1,0,1,1,
0,1,0,1,1,0,0,1,0,1,0,0,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,0,0,1,1,0,1,1,1,0,0,0,1,1,0,0,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1,0,0,1,0,1,1,
0,1,0,1,1,1,0,1,1,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,1,1,1,1,0,0,1,1,1,0,1,1,1,0,0,0,1,1,1,1,0,1,0,1,1,0,1,0,0,
0,1,1,0,0,0,0,1,1,1,0,0,0,1,1,0,0,1,0,0,0,1,1,0,1,1,1,1,0,0,0,0,1,0,1,1,1,0,1,1,0,1,0,0,0,1,1,1,1,1,0,1,0,0,0,1,0,0,0,1,1,0,0,
0,1,1,0,0,1,0,1,0,0,1,0,1,0,0,1,1,0,1,1,1,1,0,1,0,0,0,0,0,1,1,1,0,1,1,0,0,1,0,0,1,0,1,1,1,0,0,0,0,0,1,0,1,1,0,0,1,1,1,0,0,1,1,
0,1,1,0,1,0,1,0,1,1,0,1,0,1,1,1,0,1,1,0,1,0,1,0,1,0,1,1,1,0,1,1,1,0,0,1,0,1,1,0,1,0,0,0,1,1,0,0,1,0,1,0,0,1,0,0,1,0,1,0,0,1,1,
0,1,1,0,1,1,1,0,0,0,1,1,1,0,0,0,1,0,0,1,0,0,0,1,0,1,0,0,1,1,0,0,0,1,0,0,1,0,0,1,0,1,1,1,0,0,1,1,0,1,0,1,1,0,0,1,0,1,0,1,1,0,0,
0,1,1,1,0,0,1,1,1,1,0,1,1,1,1,0,1,1,0,1,0,0,0,0,1,1,0,1,1,1,0,1,0,0,0,0,1,1,0,1,1,0,1,0,0,0,1,0,0,1,1,0,1,0,0,0,1,1,0,0,0,1,1,
0,1,1,1,0,1,1,1,0,0,1,1,0,0,0,1,0,0,1,0,1,0,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0,0,1,0,0,1,0,1,1,1,0,1,1,0,0,1,0,1,0,1,0,0,1,1,1,0,0,
0,1,1,1,1,0,0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,1,0,1,1,0,0,0,1,0,0,0,0,0,0,1,1,0,1,0,0,1,0,0,0,1,1,1,0,1,0,1,1,1,1,0,0,
0,1,1,1,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1,0,1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,
1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,1,
1,0,0,0,0,1,0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,0,0,1,0,0,0,1,1,1,0,1,1,0,0,0,0,1,0,
1,0,0,0,1,0,1,1,0,0,1,1,0,0,0,1,0,0,1,0,1,1,0,0,1,1,0,1,0,1,0,1,0,0,1,0,1,1,0,1,1,1,0,1,1,1,0,1,1,0,0,1,0,1,0,1,1,1,0,0,0,1,0,
1,0,0,0,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,1,0,1,1,1,0,0,1,0,0,0,1,0,1,1,1,1,0,0,1,0,0,0,1,0,0,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,1,0,1,
1,0,0,1,0,0,1,0,0,0,1,1,1,0,0,0,1,0,0,1,0,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,0,1,1,0,1,1,1,1,0,0,1,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,
1,0,0,1,0,1,1,0,1,1,0,1,0,1,1,1,0,1,1,0,1,1,0,1,0,1,0,0,0,1,0,0,0,1,1,0,1,0,0,1,0,0,0,0,1,1,0,0,1,0,1,0,0,1,0,0,0,1,0,1,1,0,1,
1,0,0,1,1,0,0,1,0,0,1,0,1,0,0,1,1,0,1,1,1,0,1,0,1,1,1,1,1,0,0,0,1,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,0,1,0,1,1,0,0,0,0,0,1,1,0,1,
1,0,0,1,1,1,0,1,1,1,0,0,0,1,1,0,0,1,0,0,0,0,0,1,0,0,0,0,1,1,1,1,0,1,0,0,0,1,0,0,1,1,0,0,0,1,1,1,1,1,0,1,0,0,0,1,1,1,1,0,0,1,0,
1,0,1,0,0,0,0,1,1,0,1,0,0,1,0,0,0,1,0,0,0,1,1,1,1,1,0,0,1,1,1,0,1,1,0,0,0,0,1,1,0,1,1,0,1,1,1,0,0,0,1,1,1,1,0,1,1,0,0,1,0,1,0,
1,0,1,0,0,1,0,1,0,1,0,0,1,0,1,1,1,0,1,1,1,1,0,0,0,0,1,1,1,0,0,1,0,0,0,1,1,1,0,0,1,0,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,1,1,0,1,0,1,
1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,1,0,1,0,1,1,1,0,0,0,0,1,0,1,1,1,1,0,1,1,1,0,1,0,1,0,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,0,1,0,1,
1,0,1,0,1,1,1,0,0,1,0,1,1,0,1,0,1,0,0,1,0,0,0,0,0,1,1,1,0,0,1,0,0,0,1,1,0,0,0,1,0,1,0,1,1,0,1,0,1,0,1,1,0,1,0,1,1,1,0,1,0,1,0,
1,0,1,1,0,0,1,1,1,0,1,1,1,1,0,0,1,1,0,1,0,0,0,1,1,1,1,0,0,0,1,1,0,1,1,1,0,1,0,1,1,0,0,0,1,0,1,1,1,0,0,0,0,1,0,0,0,1,0,0,1,0,1,
1,0,1,1,0,1,1,1,0,1,0,1,0,0,1,1,0,0,1,0,1,0,1,0,0,0,0,1,0,1,0,0,1,0,1,0,1,0,1,0,0,1,1,1,0,1,0,0,0,1,1,1,1,0,0,1,1,0,1,1,0,1,0,
1,0,1,1,1,0,0,0,1,0,1,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,0,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,0,1,0,
1,0,1,1,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,1,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,0,1,0,1,
1,1,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,0,1,0,0,1,1,1,1,0,1,1,0,0,1,0,0,0,1,1,0,
1,1,0,0,0,1,0,0,1,0,0,0,1,1,0,1,1,1,1,1,1,0,1,0,1,1,0,0,1,0,0,1,1,0,1,0,0,1,1,1,1,1,0,1,0,1,1,0,0,0,0,1,0,0,0,1,0,1,1,1,0,0,1,
1,1,0,0,1,0,1,1,0,1,1,1,0,0,1,1,0,0,1,0,1,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,1,0,0,0,1,0,1,0,0,1,1,0,0,1,0,0,1,1,0,0,1,
1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,0,1,0,1,1,0,1,0,0,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1,1,0,1,0,1,1,0,0,1,0,0,1,1,0,0,1,1,0,
1,1,0,1,0,0,1,0,0,1,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,0,0,1,0,0,1,1,1,1,0,0,1,1,1,0,1,1,0,0,1,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,0,1,
1,1,0,1,0,1,1,0,1,0,0,1,0,1,0,1,0,1,1,0,1,1,0,0,1,1,1,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,1,1,0,0,1,1,1,0,1,0,1,0,0,0,1,0,1,0,1,1,0,
1,1,0,1,1,0,0,1,0,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,0,1,0,1,1,0,0,0,1,1,1,0,0,0,1,1,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,1,1,1,0,1,1,0,
1,1,0,1,1,1,0,1,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,1,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,0,0,0,1,1,0,1,1,1,0,1,0,0,0,1,0,0,1,
1,1,1,0,0,0,0,1,1,1,1,0,0,1,1,0,0,1,0,0,0,1,1,0,0,1,1,0,1,1,1,0,1,0,1,1,1,0,1,1,0,1,0,1,0,0,0,1,0,0,1,1,0,0,0,1,0,1,1,0,0,0,1,
1,1,1,0,0,1,0,1,0,0,0,0,1,0,0,1,1,0,1,1,1,1,0,1,1,0,0,1,1,0,0,1,0,1,1,0,0,1,0,0,1,0,1,0,1,1,1,0,1,1,0,0,1,1,0,0,1,0,0,1,1,1,0,
1,1,1,0,1,0,1,0,1,1,1,1,0,1,1,1,0,1,1,0,1,0,1,0,0,0,1,0,0,1,0,1,1,0,0,1,0,1,1,0,1,0,0,1,1,0,1,0,0,1,0,0,0,1,0,0,1,1,0,1,1,1,0,
1,1,1,0,1,1,1,0,0,0,0,1,1,0,0,0,1,0,0,1,0,0,0,1,1,1,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,1,0,0,1,0,1,1,0,1,1,1,0,0,1,0,0,1,0,0,0,1,
1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,0,1,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,1,1,0,1,1,0,1,1,0,1,0,0,1,0,0,0,1,0,0,0,1,0,1,1,1,1,0,
1,1,1,1,0,1,1,1,0,0,0,1,0,0,0,1,0,0,1,0,1,0,1,1,1,0,1,1,0,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,1,0,1,1,0,1,1,1,0,1,0,1,0,1,0,0,0,0,1,
1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,0,0,1,
1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,
]


# ------------------
# 関数の定義
# ------------------
def orthogonal_array_test(oa, X_train, y_train):
	""" 直交表をもとにした項目選択のテスト """
	X_train_norm = X_train[y_train==0]
	X_train_anom = X_train[y_train==1]
	labels = X_train.columns # 列ラベル
	sn_ratios = [] # SN比
	for arr in oa:
		arr_cols = list(itertools.compress(labels, (arr-1)**2)) # 直交表から抽出した列
		X_train_norm_ext = X_train_norm[arr_cols]
		X_train_anom_ext = X_train_anom[arr_cols]

		# MT法による異常度計算
		mts = MTS()
		mts.fit(X_train_norm_ext)
		anomaly_score = mts.predict(X_train_anom_ext)
		sn_ratio = -10*np.log10(np.sum(1/anomaly_score)/len(anomaly_score))
		sn_ratios.append(sn_ratio)
		
		# 画像保存
		# make_figure_anomaly_score(anomaly_score, y_test, OUT_DIR)
		# make_figure_break_even_point(break_even_point, score, coverage, detection)

	sn_ratios = np.array(sn_ratios)
	return sn_ratios


def orthogonal_array_sign(oa, sn_ratios):
	""" 直交表をもとにした項目ごとの平均SN比を計算 """
	sn_averages_pos = []
	sn_averages_neg = []
	for arr in oa.T:
		num = sum((arr-1)**2)
		sn_averages_pos.append(sum(itertools.compress(sn_ratios, (arr-1)**2))/num)
		sn_averages_neg.append(sum(itertools.compress(sn_ratios, arr))/num)
	sn_averages_pos = np.array(sn_averages_pos)
	sn_averages_neg = np.array(sn_averages_neg)
	return sn_averages_pos, sn_averages_neg


# ------------------
#  メイン処理
# ------------------
def main():
	initialize()
	"""
	df = pd.read_csv(IN_FILE, header=0, index_col=None, sep='\s*,\s*', engine='python')
	df = df.sample(frac=1, random_state=0) # 行シャッフル
	df = df.reset_index(drop=True) # インデックスの更新

	# データセットの作成
	target = 17600 # 上位1000件
	target_col = 'shares'
	X = df.drop([target_col, 'url'], axis=1)
	y = (df[target_col]<=target).astype(np.int32)
	X_train, X_test, y_train, y_test = train_test_split(
		X, y, test_size=0.33, random_state=47)
	"""
	
	# irisデータセットのとき
	df = pd.read_csv(IN_FILE, header=0, index_col=None, sep=',')
	df = df.sample(frac=1, random_state=0) # 行シャッフル
	df = df.reset_index(drop=True) # インデックスの更新

	# データセットの作成
	target = 'Iris-virginica'
	target_col = 'class'
	X = df.drop(target_col, axis=1)
	y = (df[target_col]==target).astype(np.int32)
	X_train, X_test, y_train, y_test = train_test_split(
		X, y, test_size=0.33, random_state=47)

	# 直交表の利用
	oa = np.reshape(L8, (8, -1)) # 直交表整形
	del_cols = range(X.shape[1], oa.shape[1])
	oa = np.delete(oa, del_cols, axis=1) # 不要列を削除
	sn_ratios = orthogonal_array_test(oa, X_train, y_train)
	sn_averages_pos, sn_averages_neg = orthogonal_array_sign(oa, sn_ratios)
	print(sn_averages_pos-sn_averages_neg) # 項目ごとのSN比平均差、プラスなら異常検知に関して有意な項目
	
	# 項目選択の結果をもとに異常検知
	sign_cols = np.where(sn_averages_pos-sn_averages_neg>=0, 1, 0) # 直交表のテストをもとに有用な変数を選択
	arr_cols = list(itertools.compress(X_train.columns, sign_cols))
	X_train_ext = X_train[arr_cols]
	X_test_ext = X_test[arr_cols]

	# MT法による異常度計算
	mts = MTS()
	mts.fit(X_train_ext[y_train==0])
	anomaly_score = mts.predict(X_test_ext)
	(break_even_point, score), (coverage, detection) = mts.break_even_point(anomaly_score, y_test)
	anomaly_score_abnormal = anomaly_score[y_test==1]
	
	# 画像保存
	make_figure_anomaly_score(anomaly_score, y_test, OUT_DIR)
	make_figure_break_even_point(break_even_point, score, coverage, detection, OUT_DIR)
	

if __name__ == '__main__':
	main()